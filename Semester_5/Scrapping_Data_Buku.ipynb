{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkxkmjyuziSSZsvgj8zGxE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reidzf8/Kuliah/blob/main/Semester_5/Scrapping_Data_Buku.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kVULH8zlj32Z"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "base_url = \"https://books.toscrape.com/\"\n",
        "catalogue_url = \"https://books.toscrape.com/catalogue/\"\n",
        "books_data = []"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi ambil detail buku\n",
        "def get_book_details(book_url, category):\n",
        "    response = requests.get(book_url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # --- Ambil data dari halaman detail ---\n",
        "    title = soup.find('div', class_='product_main').h1.text.strip()\n",
        "\n",
        "    # Rating\n",
        "    rating_tag = soup.find('p', class_='star-rating')\n",
        "    rating = rating_tag['class'][1] if rating_tag else None\n",
        "\n",
        "    # Tabel info produk\n",
        "    table = soup.find('table', class_='table table-striped')\n",
        "    details = {row.th.text.strip(): row.td.text.strip() for row in table.find_all('tr')}\n",
        "\n",
        "    # Cover image\n",
        "    cover = soup.find('div', class_='item active').img['src'].replace('../../', base_url)\n",
        "\n",
        "    # Description\n",
        "    desc_tag = soup.find('div', id='product_description')\n",
        "    description = desc_tag.find_next('p').text.strip() if desc_tag else ''\n",
        "\n",
        "    # Stock info\n",
        "    stock_info = details.get('Availability', '')\n",
        "    stock_status = \"In stock\" if \"In stock\" in stock_info else \"Out of stock\"\n",
        "    num_stock = ''.join([c for c in stock_info if c.isdigit()]) or '0'\n",
        "\n",
        "    # Masukkan data\n",
        "    books_data.append({\n",
        "        'category': category,\n",
        "        'code': details.get('UPC', ''),\n",
        "        'cover': cover,\n",
        "        'title': title,\n",
        "        'rating': rating,\n",
        "        'price (excl. tax)': details.get('Price (excl. tax)', ''),\n",
        "        'price (incl. tax)': details.get('Price (incl. tax)', ''),\n",
        "        'tax': details.get('Tax', ''),\n",
        "        'stock status': stock_status,\n",
        "        'number of stock available': num_stock,\n",
        "        'description': description,\n",
        "        'number of reviews': details.get('Number of reviews', ''),\n",
        "        'book url': book_url\n",
        "    })"
      ],
      "metadata": {
        "id": "GsnfpkPr02Ia"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi ambil semua buku dalam 1 kategori\n",
        "def scrape_category(category_url, category_name):\n",
        "    page_num = 1\n",
        "    while True:\n",
        "        url = category_url.replace(\"index.html\", f\"page-{page_num}.html\") if page_num > 1 else category_url\n",
        "        response = requests.get(url)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        books = soup.find_all('article', class_='product_pod')\n",
        "        if not books:\n",
        "            break  # Tidak ada lagi halaman berikutnya\n",
        "\n",
        "        for book in books:\n",
        "            book_url = book.h3.a['href'].replace('../../../', catalogue_url)\n",
        "            get_book_details(book_url, category_name)\n",
        "            time.sleep(0.5)  # biar tidak overload server\n",
        "\n",
        "        page_num += 1"
      ],
      "metadata": {
        "id": "j3oPAPLi06Cy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# --- Mulai scraping semua kategori ---\n",
        "home = requests.get(base_url)\n",
        "soup = BeautifulSoup(home.text, 'html.parser')\n",
        "categories = soup.find('ul', class_='nav-list').find('ul').find_all('a')\n",
        "\n",
        "for cat in categories:\n",
        "    category_name = cat.text.strip()\n",
        "    category_url = base_url + cat['href']\n",
        "    print(f\"Scraping kategori: {category_name}\")\n",
        "    scrape_category(category_url, category_name)\n",
        "\n",
        "# Buat DataFrame\n",
        "df = pd.DataFrame(books_data)\n",
        "\n",
        "# Simpan ke CSV\n",
        "df.to_csv('books_detailed_dataset.csv', index=False)\n",
        "print(f\"\\n✅ Total buku dikumpulkan: {len(df)}\")\n",
        "print(\"Data berhasil disimpan ke 'books_detailed_dataset.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHxH-VrI0_C8",
        "outputId": "cd29386c-0d61-4c37-a532-81feb8b39910"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping kategori: Travel\n",
            "Scraping kategori: Mystery\n",
            "Scraping kategori: Historical Fiction\n",
            "Scraping kategori: Sequential Art\n",
            "Scraping kategori: Classics\n",
            "Scraping kategori: Philosophy\n",
            "Scraping kategori: Romance\n",
            "Scraping kategori: Womens Fiction\n",
            "Scraping kategori: Fiction\n",
            "Scraping kategori: Childrens\n",
            "Scraping kategori: Religion\n",
            "Scraping kategori: Nonfiction\n",
            "Scraping kategori: Music\n",
            "Scraping kategori: Default\n",
            "Scraping kategori: Science Fiction\n",
            "Scraping kategori: Sports and Games\n",
            "Scraping kategori: Add a comment\n",
            "Scraping kategori: Fantasy\n",
            "Scraping kategori: New Adult\n",
            "Scraping kategori: Young Adult\n",
            "Scraping kategori: Science\n",
            "Scraping kategori: Poetry\n",
            "Scraping kategori: Paranormal\n",
            "Scraping kategori: Art\n",
            "Scraping kategori: Psychology\n",
            "Scraping kategori: Autobiography\n",
            "Scraping kategori: Parenting\n",
            "Scraping kategori: Adult Fiction\n",
            "Scraping kategori: Humor\n",
            "Scraping kategori: Horror\n",
            "Scraping kategori: History\n",
            "Scraping kategori: Food and Drink\n",
            "Scraping kategori: Christian Fiction\n",
            "Scraping kategori: Business\n",
            "Scraping kategori: Biography\n",
            "Scraping kategori: Thriller\n",
            "Scraping kategori: Contemporary\n",
            "Scraping kategori: Spirituality\n",
            "Scraping kategori: Academic\n",
            "Scraping kategori: Self Help\n",
            "Scraping kategori: Historical\n",
            "Scraping kategori: Christian\n",
            "Scraping kategori: Suspense\n",
            "Scraping kategori: Short Stories\n",
            "Scraping kategori: Novels\n",
            "Scraping kategori: Health\n",
            "Scraping kategori: Politics\n",
            "Scraping kategori: Cultural\n",
            "Scraping kategori: Erotica\n",
            "Scraping kategori: Crime\n",
            "\n",
            "✅ Total buku dikumpulkan: 1000\n",
            "Data berhasil disimpan ke 'books_detailed_dataset.csv'\n"
          ]
        }
      ]
    }
  ]
}